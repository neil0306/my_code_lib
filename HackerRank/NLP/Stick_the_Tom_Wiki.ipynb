{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.hackerrank.com/challenges/stitch-the-torn-wiki/problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Format\n",
    "\n",
    "An Integer N on the first line. This is followed by 2N+1 lines.\n",
    "\n",
    "Text fragments (numbered 1 to N) from Set A, each on a new line (so a total of N lines).\n",
    "\n",
    "A separator with five asterisk marks \"*\" which indicates the end of Set A and beginning of Set B.\n",
    "\n",
    "Text fragments (numbered 1 to N) from Set B, each on a new line (so a total of N lines).\n",
    "\n",
    "## Output Format\n",
    "\n",
    "N lines, each containing one integer.\n",
    "\n",
    "The i-th line should contain an integer j such that the i-th element of Set A and the j-th element of Set B are a pair, i.e., both originally came from the same block of text/Wikipedia article.\n",
    "\n",
    "## Constraints\n",
    "\n",
    "1 <= N <= 100\n",
    "\n",
    "No text fragment will have more than 10000 characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Input\n",
    "(Please note that the real inputs used will be much longer, and generated with text blocks with 500-1000 words. This is for explanatory purposes only)\n",
    "\n",
    "```txt\n",
    "3\n",
    "Delhi (also known as the National Capital Territory of India) is a metropolitan region in India that includes the national capital city, New Delhi. With a population of 22 million in 2011, it is the world's second most populous city and the largest city in India in terms of area. The NCT and its urban region have been given the special status of National Capital Region (NCR) under the Constitution of India's 69th amendment act of 1991. The NCR includes the neighbouring cities of Baghpat, Gurgaon, Sonepat, Faridabad, Ghaziabad, Noida, Greater Noida and other nearby towns, and has nearly 22.2 million residents.    \n",
    "Seattle is a coastal seaport city and the seat of King County, in the U.S. state of Washington. With an estimated 634,535 residents as of 2012, Seattle is the largest city in the Pacific Northwest region of North America and one of the fastest-growing cities in the United States. The Seattle metropolitan area of around 4 million inhabitants is the 15th largest metropolitan area in the nation.[6] The city is situated on a narrow isthmus between Puget Sound (an inlet of the Pacific Ocean) and Lake Washington, about 100 miles (160 km) south of the Canada–United States border. A major gateway for trade with Asia, Seattle is the 8th largest port in the United States and 9th largest in North America in terms of container handling.  \n",
    "Martin Luther OSA (10 November 1483 – 18 February 1546) was a German monk, Catholic priest, professor of theology and seminal figure of a reform movement in 16th century Christianity, subsequently known as the Protestant Reformation.[1] He strongly disputed the claim that freedom from God's punishment for sin could be purchased with money. He confronted indulgence salesman Johann Tetzel, a Dominican friar, with his Ninety-Five Theses in 1517. His refusal to retract all of his writings at the demand of Pope Leo X in 1520 and the Holy Roman Emperor Charles V at the Diet of Worms in 1521 resulted in his excommunication by the Pope and condemnation as an outlaw by the Emperor.\n",
    "*****  \n",
    "The Seattle area had been inhabited by Native Americans for at least 4,000 years before the first permanent European settlers. Arthur A. Denny and his group of travelers, subsequently known as the Denny Party, arrived at Alki Point on November 13, 1851. The settlement was moved to its current site and named \"Seattle\" in 1853, after Chief Si'ahl of the local Duwamish and Suquamish tribes.  \n",
    "Although technically a federally administered union territory, the political administration of the NCT of Delhi today more closely resembles that of a state of India, with its own legislature, high court and an executive council of ministers headed by a Chief Minister. New Delhi is jointly administered by the federal government of India and the local government of Delhi, and is the capital of the NCT of Delhi.  \n",
    "Luther taught that salvation and subsequently eternity in heaven is not earned by good deeds but is received only as a free gift of God's grace through faith in Jesus Christ as redeemer from sin and subsequently eternity in hell. His theology challenged the authority of the Pope of the Roman Catholic Church by teaching that the Bible is the only source of divinely revealed knowledge from God and opposed sacerdotalism by considering all baptized Christians to be a holy priesthood. Those who identify with these, and all of Luther's wider teachings, are called Lutherans.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Output\n",
    "\n",
    "2  \n",
    "1  \n",
    "3  \n",
    "\n",
    "\n",
    "### Explanation\n",
    "```txt\n",
    "The first, second and third text fragment of Set A are about Delhi, Seattle and Martin Luther respectively.\n",
    "In set B, the paragraph on Delhi, is the second text fragment.\n",
    "The paragraph on Seattle is the first text fragment in Set B.\n",
    "The paragraph on Martin Luther Kind is the third text fragment in Set B.\n",
    "So, the expected output is 2, 1, 3 respectively.\n",
    "```\n",
    "\n",
    "## Scoring\n",
    "```txt\n",
    "A sample test case with twenty paragraphs is provided to you when you Compile and Test.\n",
    "Extensive training data is not required for this challenge. The weightage for a test case will be proportional to the number of tests (Articles) which it contains. This works out to a ratio of 1:2 (Sample Test: Hidden Test).\n",
    "Score = M * (C)/N Where M is the Maximum Score for the test case.\n",
    "C = Number of correct answers in your output.\n",
    "N = Total number of Wikipedia Articles (which were split into 2N fragments and divided into Set A and Set B respectively).\n",
    "```\n",
    "\n",
    "Note:\n",
    "    Submissions will be disqualified if it is evident that the code has been written in such a way that the sample test case answers are hard-coded, or similar approaches, where the answer is not computed, but arrived at by trying to ensure the code matches the sample answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 1 (score: 92.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def find_matching_fragments(N, fragments):\n",
    "    set_a = fragments[:N]\n",
    "    set_b = fragments[N+1:]\n",
    "    \n",
    "    # 文本预处理\n",
    "    vectorizer = CountVectorizer().fit(set_a + set_b)\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    \n",
    "    # 计算TF-IDF\n",
    "    tfidf_a = tfidf_transformer.fit_transform(vectorizer.transform(set_a))\n",
    "    tfidf_b = tfidf_transformer.transform(vectorizer.transform(set_b))\n",
    "    \n",
    "    # 计算余弦相似度\n",
    "    similarities = cosine_similarity(tfidf_a, tfidf_b)\n",
    "    \n",
    "    # 匹配片段\n",
    "    result = []\n",
    "    for i in range(N):\n",
    "        most_similar_index = np.argmax(similarities[i])\n",
    "        result.append(most_similar_index + 1)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 读取输入\n",
    "N = int(input())\n",
    "fragments = [input().strip() for _ in range(2 * N + 1)]\n",
    "\n",
    "# 找到匹配的片段\n",
    "result = find_matching_fragments(N, fragments)\n",
    "\n",
    "# 输出结果\n",
    "for res in result:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 2 (score: 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 将文本分割成单词，并去除特殊字符\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    return words\n",
    "\n",
    "def create_word_count_dict(texts):\n",
    "    # 创建词频字典\n",
    "    word_count_dicts = [Counter(preprocess_text(text)) for text in texts]\n",
    "    return word_count_dicts\n",
    "\n",
    "def create_global_word_count_dict(word_count_dicts):\n",
    "    # 创建全局词频字典\n",
    "    global_word_count = Counter()\n",
    "    for word_count in word_count_dicts:\n",
    "        global_word_count.update(word_count)\n",
    "    return global_word_count\n",
    "\n",
    "def normalize_word_count_dict(word_count_dict, global_word_count):\n",
    "    # 归一化词频字典\n",
    "    total_words = sum(global_word_count.values())\n",
    "    normalized_dict = {word: count / global_word_count[word] for word, count in word_count_dict.items()}\n",
    "    return normalized_dict\n",
    "\n",
    "def dict_to_vector(word_count_dict, global_word_count):\n",
    "    # 将词频字典转换为向量\n",
    "    vector = np.zeros(len(global_word_count))\n",
    "    for i, word in enumerate(global_word_count):\n",
    "        if word in word_count_dict:\n",
    "            vector[i] = word_count_dict[word]\n",
    "    return vector\n",
    "\n",
    "def find_matching_fragments(N, fragments):\n",
    "    set_a = fragments[:N]\n",
    "    set_b = fragments[N+1:]\n",
    "    \n",
    "    # 创建词频字典\n",
    "    word_count_dicts_a = create_word_count_dict(set_a)\n",
    "    word_count_dicts_b = create_word_count_dict(set_b)\n",
    "    \n",
    "    # 创建全局词频字典\n",
    "    global_word_count = create_global_word_count_dict(word_count_dicts_a + word_count_dicts_b)\n",
    "    \n",
    "    # 归一化词频字典\n",
    "    normalized_dicts_a = [normalize_word_count_dict(word_count, global_word_count) for word_count in word_count_dicts_a]\n",
    "    normalized_dicts_b = [normalize_word_count_dict(word_count, global_word_count) for word_count in word_count_dicts_b]\n",
    "    \n",
    "    # 将词频字典转换为向量\n",
    "    vectors_a = np.array([dict_to_vector(word_count, global_word_count) for word_count in normalized_dicts_a])\n",
    "    vectors_b = np.array([dict_to_vector(word_count, global_word_count) for word_count in normalized_dicts_b])\n",
    "    \n",
    "    # 计算余弦相似度\n",
    "    similarity_matrix = cosine_similarity(vectors_a, vectors_b)\n",
    "    \n",
    "    # 找到最佳匹配\n",
    "    row_ind, col_ind = linear_sum_assignment(-similarity_matrix)    # 本质上就是\"匈牙利算法\"; \n",
    "                                                                    # 线性分配问题的目标是找到一种分配方式，使得总成本最小化。因为我们需要找相似度最高的, 刚好与定义相反发, 所以取负值\n",
    "                                                                    # row_ind[i] 表示集合 A 中的第 i 个片段，col_ind[i] 表示集合 B 中与之匹配的片段。\n",
    "    \n",
    "    return col_ind + 1\n",
    "\n",
    "# 读取输入\n",
    "N = int(input())\n",
    "fragments = [input().strip() for _ in range(2 * N + 1)]\n",
    "\n",
    "# 找到匹配的片段\n",
    "result = find_matching_fragments(N, fragments)\n",
    "\n",
    "# 输出结果\n",
    "for res in result:\n",
    "    print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
