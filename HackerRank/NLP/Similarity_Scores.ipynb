{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.hackerrank.com/challenges/nlp-similarity-scores/problem?isFullScreen=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are provided with four documents, numbered 1 to 4, each with a single sentence of text. Determine the identifier of the document  which is the most similar to the first document, as computed according to the TF-IDF scores.\n",
    "\n",
    "```txt\n",
    "1. I'd like an apple.\n",
    "2. An apple a day keeps the doctor away.\n",
    "3. Never compare an apple to an orange.\n",
    "4. I prefer scikit-learn to orange.\n",
    "```\n",
    "\n",
    "Output the integer  (which may be either 2 or 3 or 4), leaving no leading or trailing spaces.\n",
    "\n",
    "You may either compute the answer manually and submit it in plain-text mode, or submit a program which computes the answer, in a language of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "documents = [\n",
    "    \"I'd like an apple.\",\n",
    "    \"An apple a day keeps the doctor away.\",\n",
    "    \"Never compare an apple to an orange.\",\n",
    "    \"I prefer scikit-learn to orange.\"\n",
    "]\n",
    "\n",
    "def preprocess(text):\n",
    "    return text.lower().replace('.', '').replace(',', '').split()\n",
    "\n",
    "def compute_tf(word_dict, doc):  # 分别计算每个文档中, 每个词出现的频率(概率)\n",
    "    tf_dict = {}\n",
    "    doc_count = len(doc)\n",
    "    for word, count in word_dict.items():\n",
    "        tf_dict[word] = count / float(doc_count)   # 每个词在文档中出现的次数 / 文档中的总词数 ==> 每个词出现的频率(概率)\n",
    "    return tf_dict\n",
    "\n",
    "def compute_idf(doc_list):\n",
    "    idf_dict = {}\n",
    "    N = len(doc_list)\n",
    "    \n",
    "    # 统计所有文档中, 每个词出现的次数\n",
    "    for doc in doc_list:\n",
    "        for word in doc:\n",
    "            if word in idf_dict:\n",
    "                idf_dict[word] += 1\n",
    "            else:\n",
    "                idf_dict[word] = 1\n",
    "    \n",
    "    # 计算idf, idf = log(文档总数 / 该词在所有文档中出现的次数) \n",
    "    for word, count in idf_dict.items():\n",
    "        idf_dict[word] = math.log(N / float(count))   # log(文档总数 / 该词在所有文档中出现的次数)\n",
    "    return idf_dict\n",
    "\n",
    "def compute_tfidf(tf_doc, idf_dict):\n",
    "    tfidf = {}\n",
    "    for word, tf_val in tf_doc.items():\n",
    "        tfidf[word] = tf_val * idf_dict.get(word, 0)  # 词在当前文档中的频率 * log(文档总数 / 该词在所有文档中出现的次数)\n",
    "    return tfidf\n",
    "\n",
    "def cosine_similarity(vec1, vec2):  # 余弦相似度: 内积 / (向量1的模 * 向量2的模)\n",
    "    \n",
    "    # 计算内积: 取相同词的tfidf值的乘积, 然后求和\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())          # 使用集合的交集操作, &操作符表示交集, 得到两个文档中共同出现的词\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])  # 取出共同出现的词, 计算两个文档中这些词的tfidf值的乘积, 然后求和\n",
    "    \n",
    "    # 计算向量1的模和向量2的模: 分别取出两个文档中所有词的tfidf值的平方, 然后求和, 再开方\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    \n",
    "    # 计算模的乘积\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "    \n",
    "    # 防止分母为0\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "preprocessed_docs = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# count words in each document, eg. {\"i'd\":1, \"like\":1, \"an\":1, \"apple\":1}\n",
    "word_counts = [Counter(doc) for doc in preprocessed_docs]\n",
    "\n",
    "tf_docs = [compute_tf(word_count, doc) for word_count, doc in zip(word_counts, preprocessed_docs)]\n",
    "\n",
    "idf_dict = compute_idf(preprocessed_docs)\n",
    "\n",
    "tfidf_docs = [compute_tfidf(tf_doc, idf_dict) for tf_doc in tf_docs]\n",
    "\n",
    "similarities = [cosine_similarity(tfidf_docs[0], tfidf_docs[i]) for i in range(1, len(tfidf_docs))]\n",
    "\n",
    "most_similar_document_index = similarities.index(max(similarities)) + 2\n",
    "\n",
    "print(most_similar_document_index)   # print(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comfyui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
